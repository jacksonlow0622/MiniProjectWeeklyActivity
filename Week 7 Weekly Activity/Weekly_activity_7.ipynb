{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af29a2c3",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ddd1a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab25e3",
   "metadata": {},
   "source": [
    "# Weekly activity 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9084c",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7012cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('winter.jfif', 0)\n",
    "\n",
    "# histogram equalization\n",
    "eq = cv.equalizeHist(img)\n",
    "eq2 = cv.equalizeHist(eq)\n",
    "\n",
    "cv.imshow('result', np.hstack((img, eq, eq2)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac92eb",
   "metadata": {},
   "source": [
    "Comment: There is no difference between first and second output image since it is already equalized. It can't be equalized anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55300473",
   "metadata": {},
   "source": [
    "# Question 2.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347fe6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif', 0)\n",
    "\n",
    "sobelx = cv.Sobel(img, cv.CV_64F, 1, 0, ksize = 1)\n",
    "sobely = cv.Sobel(img, cv.CV_64F, 0, 1, ksize = 1)\n",
    "\n",
    "grad_mag_L2 = cv.magnitude(sobelx, sobely)\n",
    "grad_mag_L2 = cv.convertScaleAbs(grad_mag_L2)\n",
    "\n",
    "cv.imshow('result', np.hstack((img, grad_mag_L2)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e96cb",
   "metadata": {},
   "source": [
    "Comment: Kernel size of 1 is most appropriate to be chosen as it produce result with the minimal noise and there is less white line (noises) in the images compared to kernel size of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31227536",
   "metadata": {},
   "source": [
    "# Question 2.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "060149c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blur = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "sobelx_blur = cv.Sobel(img_blur, cv.CV_64F, 1, 0, ksize = 1)\n",
    "sobely_blur = cv.Sobel(img_blur, cv.CV_64F, 0, 1, ksize = 1)\n",
    "\n",
    "grad_mag_L2_blur = cv.magnitude(sobelx_blur, sobely_blur)\n",
    "grad_mag_L2_blur = cv.convertScaleAbs(grad_mag_L2_blur)\n",
    "\n",
    "cv.imshow('result', np.hstack((img, grad_mag_L2, grad_mag_L2_blur)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66aa398",
   "metadata": {},
   "source": [
    "# Question 2.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cead6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = cv.Laplacian(img_blur, cv.CV_64F, ksize = 3)\n",
    "\n",
    "laplacian_8u = cv.convertScaleAbs(laplacian)\n",
    "\n",
    "cv.imshow('result', laplacian_8u)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a01df5",
   "metadata": {},
   "source": [
    "Question 2 Conclusion: \n",
    "The image processing pathway that is optimal is apply the Gaussian blurring for smoothing the image first, then perform the edge detection using Sobel operator. The reason is that the Gaussian blurring will first reduce the noises in the image first. Then, the edge detection using Sobel operator with kernel size of 1 have the minimal noises in the image processed among all the different techniques applied in Question 2 and the image processed preserves the edge of object better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e7c55",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e3a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('pineapple.jfif', 0)\n",
    "blur = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "# Sobel\n",
    "sobelx = cv.Sobel(blur, cv.CV_64F, 1, 0, ksize = 3)\n",
    "sobely = cv.Sobel(blur, cv.CV_64F, 0, 1, ksize = 3)\n",
    "grad_mag_L2 = cv.magnitude(sobelx, sobely)\n",
    "grad_mag_L2 = cv.convertScaleAbs(grad_mag_L2)\n",
    "\n",
    "# Laplacian\n",
    "laplacian = cv.Laplacian(blur, cv.CV_64F, ksize = 3)\n",
    "laplacian_8u = cv.convertScaleAbs(laplacian)\n",
    "\n",
    "# prewitt\n",
    "kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "img_prewittx = cv.filter2D(blur, -1, kernelx)\n",
    "img_prewitty = cv.filter2D(blur, -1, kernely)\n",
    "\n",
    "# Scharr\n",
    "scharrx = cv.Scharr(blur, cv.CV_64F, 1, 0, 3)\n",
    "scharry = cv.Scharr(blur, cv.CV_64F, 0, 1, 3)\n",
    "grad_mag_L2_scharr = cv.magnitude(scharrx, scharry)\n",
    "grad_mag_L2_scharr = cv.convertScaleAbs(grad_mag_L2_scharr)\n",
    "\n",
    "# Canny\n",
    "output_canny = cv.Canny(blur, 100, 200, 3)\n",
    "\n",
    "cv.imshow('result', np.hstack((img, grad_mag_L2, \n",
    "                               laplacian_8u, img_prewittx + img_prewitty, \n",
    "                               grad_mag_L2_scharr, output_canny)))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e1bd02",
   "metadata": {},
   "source": [
    "Comment on results:\n",
    "* Sobel: Result with most edges of object detected and edges of object is preserved.\n",
    "* Laplacian: Edge with similar contrast are hard to be detected.\n",
    "* Prewitt: Results are similar to Sobel but less edges of object is detected on same colour.\n",
    "* Scharr derivatives: All the edges in the image is detected and hard to differentiate the object in the image.\n",
    "* Canny operators: The cleanest result is shown and the cleanest edge is detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d80a0",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e8aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('electronic.jfif')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # convert to grayscale\n",
    "\n",
    "# CLAHE\n",
    "clahe = cv.createCLAHE(clipLimit = 7.0, tileGridSize = (15, 15))\n",
    "dst = clahe.apply(gray)\n",
    "\n",
    "# blur the image then threshold\n",
    "blur = cv.GaussianBlur(dst, (7, 7), 0)\n",
    "_, th = cv.threshold(blur, 190, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# find contour\n",
    "contour, hierarchy = cv.findContours(th, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# loop the contour to find the laptop contour\n",
    "for c in contour:\n",
    "    area = cv.contourArea(c)\n",
    "    if area >= 900:\n",
    "        cnt = c\n",
    "        x, y, w, h = cv.boundingRect(cnt)\n",
    "        cv.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "cv.imshow('result', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3006d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
